-
    UID: "dipanjan"
    thumbnail: "dipanjan2.png"
    speaker: "Dipanjan Das"
    institution: "Google AI"
    url: https://www.dipanjandas.com/
    title: "Trustworthy Natural Language Generation with Communicative Goals"
    abstract: "While recent work in large language models have made natural language generation fluent, these models suffer from content “hallucination”, where model-generated statements are not attributable to sources in communicative scenarios (e.g. summarization, question answering and responses in dialogue systems). Furthermore, evaluation of generation systems remains challenging: (1) human evaluation studies are not reproducible and there is a lack of common benchmarking for diverse tasks, and (2) popular automatic evaluation methods such as BLEU and ROUGE correlate poorly with human judgments. In this talk, I will present a body of work that attempts to solve the above problems for a variety of natural language generation problems and showcase a vision towards future work in this area."
    bio: "Dipanjan Das is a Principal Scientist at Google Research, based in New York City. He leads teams of researchers distributed between New York, London, Berlin, Amsterdam and Seattle focused on language technologies. Dipanjan’s research focus is on natural language generation, grounding and attribution in generative models and model interpretability. Before joining Google, Dipanjan completed a Ph.D. from the Language Technologies Institute, School of Computer Science at Carnegie Mellon University in 2012. In 2005, he completed a B.Tech. in Computer Science and Engineering from IIT Kharagpur. His work has received paper awards at the ACL and EMNLP conferences; he serves as action editor for the Transactions of the Association for Computational Linguistics and the ACL Rolling Review and as senior committee member at various *ACL and machine learning venues."
-
    UID: "eisner"
    thumbnail: "jason_eisner.jpeg"
    speaker: "Jason Eisner"
    institution: "Johns Hopkins University/Semantic Machines"
    url: https://www.cs.jhu.edu/~jason/
    title: "TBD"
    abstract: "TBD"
    bio: "TBD"
-
    UID: "douwe"
    thumbnail: "douwe.jpeg"
    speaker: "Douwe Kiela"
    institution: "HuggingFace"
    url: https://douwekiela.github.io/
    title: "Rethinking benchmarking in AI: Evaluation-as-a-Service and Dynamic Adversarial Data Collection"
    abstract: "The current benchmarking paradigm in AI has many issues: benchmarks saturate quickly, are susceptible to overfitting, contain exploitable annotator artifacts, have unclear or imperfect evaluation metrics, and do not measure what we really care about. I will talk about my work on trying to rethink the way we do benchmarking in AI. First, I’ll go into our work at Hugging Face on establishing better best practices for the comprehensive evaluation of data and models, through the open source Evaluate library and the Evaluation on the Hub project. Second, I’ll talk about Dynabench, a research platform that facilitates human and model in the loop data collection and evaluation, as well as the progress the team has been making in exploring the dynamic adversarial data collection paradigm."
    bio: "Douwe Kiela is the Head of Research at Hugging Face. Before, he was a Research Scientist at Facebook AI Research. His current research interests lie in developing better models for (grounded, multi-agent) language understanding and better tools for evaluation and benchmarking. He received his PhD and MPhil from the University of Cambridge. Before that, he did a BSc in Liberal Arts & Sciences at Utrecht University with a double major in Cognitive Artificial Intelligence and Philosophy; and an MSc in Logic at the University of Amsterdam's ILLC."

-
    UID: "partha"
    thumbnail: "partha.jpeg"
    speaker: "Partha Pratim Talukdar"
    institution: "Google Research/Indian Institute of Science"
    url: https://talukdar.net/
    title: "Temporal and Multilingual Knowledge Graphs"
    abstract: "The world is dynamic and Knowledge Graphs (KG) should reflect this time-varying nature. Temporal KGs provide a mechanism to represent this dynamism through time-scoped edges. While question answering over traditional KGs have received quite a bit of attention, QA over Temporal KGs is still in early stages. In the first part of the talk, I shall present the challenges and approaches for Temporal KGQA. In the second part of the talk, I shall outline the challenges with severe sparsity in KGs when going beyond English. I shall present the need along with an approach to link KG with text in a cross-lingual manner. I shall conclude the talk with open problems in these areas."
    bio: "Partha is a Researcher at Google Research, Bangalore where he leads the NLP group. He is also a faculty member (on leave) at IISc Bangalore. Partha founded KENOME, an enterprise Knowledge graph company with the mission to help enterprises make sense of unstructured data. Previously, Partha was a Postdoctoral Fellow in the Machine Learning Department at Carnegie Mellon University, working with Tom Mitchell on the NELL project. Partha is broadly interested in NLP and Machine Learning, and in making language technologies more inclusive. Partha is a recipient of several awards, including an Outstanding Paper Award at ACL 2019. He is a co-author of a book on Graph-based Semi-Supervised Learning. Homepage: https://parthatalukdar.github.io"

-
    UID: "Angeliki"
    thumbnail: "angeliki.jpeg"
    speaker: "Angeliki Lazaridou"
    institution: "Deepmind"
    url: http://angelikilazaridou.github.io/
    title: "TBD"
    abstract: "TBD"
    bio: "TBD"

-
    UID: "lewandowsky"
    thumbnail: "lewandowsky.png"
    speaker: "Stephan Lewandowsky"
    institution: "University of Bristol"
    url: https://www.cogsciwa.com/
    title: "Anti-vaccination arguments: a conceptual taxonomy and a machine-learning model"
    abstract: "The proliferation of anti-vaccination arguments is a threat to the success of many immunisation programmes. Effective rebuttal of contrarian arguments requires an approach that goes beyond addressing flaws in the arguments, by also considering the attitude roots---that is, the underlying psychological attributes driving a person's belief---of opposition to vaccines. Through a preregistered systematic literature review and thematic analysis of anti-vaccination arguments, we developed a hierarchical taxonomy that relates common arguments and themes to 11 attitude roots that explain why an individual might express opposition to vaccination. We further validated our taxonomy on COVID-19 anti-vaccination misinformation, through a combination of human coding and machine learning using natural language processing algorithms. Overall, the taxonomy serves as a theoretical framework to link expressed opposition of vaccines to their underlying psychological processes. This enables future work to develop targeted rebuttals and other interventions that address the underlying motives of anti-vaccination arguments."
    bio: "TBD"

-
    UID: "winn"
    thumbnail: "john_winn.png"
    speaker: "John Winn"
    institution: "Microsoft Research"
    url: https://www.microsoft.com/en-us/research/people/jwinn/
    title: "Project Alexandria in Viva Topics: AKBC in practice"
    abstract: "At AKBC 2019, we presented Project Alexandria as a solution to inferring a knowledge base completely automatically from unstructured data. Since then, we have built Alexandria into the heart of a new Microsoft product called Viva Topics, launched last year. Viva Topics automatically constructs a knowledge base from an organization’s documents and intranet pages, and surfaces it across a wide range of Microsoft applications including SharePoint, Teams, Outlook and more. \n\n
In this talk, I will explore all the challenges the Alexandria team has encountered in transitioning from an academic project to a high quality, scalable production system . These challenges include enabling continual expansion of the knowledge base as new data arrives, allowing people to edit the knowledge base as it is being constructed, bringing together knowledge from a wide variety of structured and unstructured sources, and integrating knowledge across languages. Today, the Alexandria system can discover hundreds of types of entities from tens of millions of documents whilst keeping these entities updated, and integrated with human edits, as the organization evolves. The result is a solution which brings organizational knowledge effortlessly to the fingertips of users across the Microsoft ecosystem."
    bio: "John Winn is a senior principal researcher in machine learning from Microsoft Research in Cambridge. In his career, he has worked on large scale automated message passing systems and probabilistic programming, through the development of the Infer.NET framework. He has published on machine learning applications in healthcare, gaming, computational biology and machine vision, and his work has been incorporated into products like the Xbox Kinect and Outlook. In the last decade, he has focused on automatic knowledge base construction using probabilistic programming in the form of Project Alexandria and, more recently, on delivering this work into the new Viva Topics product."

-
    UID: "raquel"
    thumbnail: "raquel_portrait2_2022.png"
    speaker: "Raquel Fernández"
    institution: "University of Amsterdam"
    url: https://staff.fnwi.uva.nl/r.fernandezrovira/
    title: "Unraveling the implicit linguistic knowledge learned by pre-trained neural models"
    abstract: "It has become increasingly clear that large pre-trained neural models are capable of learning and representing a broad range of linguistic knowledge. However, many open questions remain about the extent to which this is the case for specific linguistic abilities. A rich literature has emerged in the last few years investigating these issues, often taking inspiration from methodologies developed in psycholinguistics, neurolinguistics, and language acquisition research, where the same questions have been asked about the human mind/brain for centuries. I will discuss two of our recent studies that build on this tradition: a study that turns to `structural priming’ — a phenomenon prevalent in human dialogue — to investigate the degree to which language models encode abstract structural information, and a study focused on multimodal pre-trained models, which explores whether, and to what extent, leveraging visual information makes the representations learned by these models closer to human lexical semantic representations."
    bio: "Raquel Fernández is Full Professor of Computational Linguistics and Dialogue Systems at the University of Amsterdam, where she leads the Dialogue Modelling Group. Raquel received her PhD from King's College London and, before moving to Amsterdam, held research positions at the University of Potsdam and at Stanford University. Over her career, she has been awarded several prestigious personal fellowships by the Dutch Research Council and is currently the recipient of a European Research Council (ERC) Consolidator Grant. Her interests revolve around language use in context, including computational semantics and pragmatics, dialogue interaction, visually-grounded language processing, and language learning, among others. Her lab carries out research on these topics with an approach at the interface of natural language processing, cognitive science, and AI."

-
    UID: "jessie"
    thumbnail: "jessie.jpeg"
    speaker: "Jessica D. Tenenbaum"
    institution: "North Carolina Department of Health and Human Services/Duke University"
    url: https://www.ncdhhs.gov/about/administrative-offices/data-office/jessie-tenenbaum
    title: "Data driven policy for pandemic response: data, knowledge, and action well outside of the ivory tower"
    abstract: "The \"central dogma\" of informatics, it has been said, is turning data into information and information into knowledge. Some take this framework further- knowledge informs action. Moreover, in the Learning Health System model, action begets more real-world data, which can be converted into information, etc. In 2019, North Carolina's Department of Health and Human Services created the NC DHHS Data Office in recognition of the data's importance, and potential, to drive policy and decision making. With vast troves of data collected across siloed government services- locally, regionally, and nationally- there is great potential to turn that data into knowledge, and knowledge into action. What became clear, both before and after the start of the pandemic, was that there are many steps to climb in the real world before we can enter this virtuous cycle. The speaker will describe the view from the trenches of US state government pandemic response, early pandemic data strategy, and how machine learning was used, and not used, in this real world use case."
    bio: "TBD"

-
    UID: "hehe"
    thumbnail: "hehe.jpeg"
    speaker: He He
    institution: New York University
    url: https://hhexiy.github.io/
    title: "Overcoming spurious correlations in natural language understanding"
    abstract: "Model robustness and spurious correlations have received increasing attention in the NLP community from method development to model interpretation. The core question is how to build models that are \"right for the right reasons\" and not taking shortcuts.  In this talk, I will go through both success stories and unexpected failures in the quest for robust natural language understanding. Then, I will come back to the very basic question of what spurious features mean in NLP tasks, and argue that different types of spurious features come with unique challenges and require different treatment. I will conclude with lessons learned and thoughts for the future."
    bio: "He He is an Assistant Professor in the Department of Computer Science and the Center for Data Science at New York University. She obtained her PhD in Computer Science at the University of Maryland, College Park. Before joining NYU, she spent a year at AWS AI and was a post-doc at Stanford University before that. She is interested in building robust and trustworthy NLP systems in human-centered settings. Her recent research focus includes robust language understanding, collaborative text generation, and understanding capabilities and issues of large language models.
"
    
